{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control random processes\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[   8    1]\n",
      " [  16    3]\n",
      " [  32   28]\n",
      " [  64  264]\n",
      " [ 128  848]\n",
      " [ 256  771]\n",
      " [ 512   84]\n",
      " [1024    1]]\n",
      "1\n",
      "[[ 32  35]\n",
      " [ 64 337]\n",
      " [128 846]\n",
      " [256 698]\n",
      " [512  84]]\n",
      "1.5\n",
      "[[ 32  21]\n",
      " [ 64 186]\n",
      " [128 808]\n",
      " [256 857]\n",
      " [512 128]]\n",
      "2\n",
      "[[  8   3]\n",
      " [ 16 126]\n",
      " [ 32 556]\n",
      " [ 64 850]\n",
      " [128 425]\n",
      " [256  39]\n",
      " [512   1]]\n",
      "2.5\n",
      "[[ 32  30]\n",
      " [ 64 227]\n",
      " [128 866]\n",
      " [256 806]\n",
      " [512  71]]\n",
      "3\n",
      "[[  16    1]\n",
      " [  32   12]\n",
      " [  64  140]\n",
      " [ 128  582]\n",
      " [ 256 1101]\n",
      " [ 512  164]]\n"
     ]
    }
   ],
   "source": [
    "for duration in [.5, 1, 1.5, 2, 2.5, 3]:\n",
    "    print(duration)\n",
    "    network = NeuralNetwork()\n",
    "    network.train(duration=duration, game_penalty_type='scores',\n",
    "                 forget_after=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  32   25]\n",
      " [  64  180]\n",
      " [ 128  711]\n",
      " [ 256  846]\n",
      " [ 512  237]\n",
      " [1024    1]]\n",
      "[[ 16   3]\n",
      " [ 32  33]\n",
      " [ 64 251]\n",
      " [128 751]\n",
      " [256 903]\n",
      " [512  59]]\n",
      "[[  16    4]\n",
      " [  32   63]\n",
      " [  64  338]\n",
      " [ 128  801]\n",
      " [ 256  714]\n",
      " [ 512   78]\n",
      " [1024    2]]\n",
      "[[  8   8]\n",
      " [ 16 105]\n",
      " [ 32 581]\n",
      " [ 64 967]\n",
      " [128 326]\n",
      " [256  13]]\n",
      "[[  8   1]\n",
      " [ 16  30]\n",
      " [ 32 164]\n",
      " [ 64 517]\n",
      " [128 730]\n",
      " [256 510]\n",
      " [512  48]]\n",
      "[[ 16   5]\n",
      " [ 32 102]\n",
      " [ 64 542]\n",
      " [128 801]\n",
      " [256 499]\n",
      " [512  51]]\n"
     ]
    }
   ],
   "source": [
    "for duration in [1,2,3]:\n",
    "    for learning_rate in [.001,.01]:\n",
    "        network = NeuralNetwork()\n",
    "        network.train(duration=duration, move_penalty_type='nonzero', forget_after=60,\n",
    "                     game_penalty_type='scores', lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores 0.001 20\n",
      "[[  32   13]\n",
      " [  64  133]\n",
      " [ 128  626]\n",
      " [ 256 1085]\n",
      " [ 512  143]]\n",
      "scores 0.001 60\n",
      "[[  32    5]\n",
      " [  64  102]\n",
      " [ 128  658]\n",
      " [ 256  998]\n",
      " [ 512  234]\n",
      " [1024    3]]\n",
      "scores 0.001 100\n",
      "[[ 32   6]\n",
      " [ 64 190]\n",
      " [128 803]\n",
      " [256 903]\n",
      " [512  98]]\n",
      "scores 0.01 20\n",
      "[[ 16   1]\n",
      " [ 32  17]\n",
      " [ 64 157]\n",
      " [128 830]\n",
      " [256 895]\n",
      " [512 100]]\n",
      "scores 0.01 60\n",
      "[[ 32  21]\n",
      " [ 64 253]\n",
      " [128 782]\n",
      " [256 876]\n",
      " [512  68]]\n",
      "scores 0.01 100\n",
      "[[ 16   3]\n",
      " [ 32  42]\n",
      " [ 64 341]\n",
      " [128 994]\n",
      " [256 589]\n",
      " [512  31]]\n",
      "scores 0.1 20\n",
      "[[  8   4]\n",
      " [ 16  94]\n",
      " [ 32 489]\n",
      " [ 64 862]\n",
      " [128 518]\n",
      " [256  33]]\n",
      "scores 0.1 60\n",
      "[[  8   5]\n",
      " [ 16  93]\n",
      " [ 32 563]\n",
      " [ 64 815]\n",
      " [128 480]\n",
      " [256  44]]\n",
      "scores 0.1 100\n",
      "[[ 16   1]\n",
      " [ 32  34]\n",
      " [ 64 250]\n",
      " [128 781]\n",
      " [256 887]\n",
      " [512  47]]\n",
      "log2_max 0.001 20\n",
      "[[ 32  14]\n",
      " [ 64 202]\n",
      " [128 789]\n",
      " [256 869]\n",
      " [512 126]]\n",
      "log2_max 0.001 60\n",
      "[[ 16   1]\n",
      " [ 32  39]\n",
      " [ 64 230]\n",
      " [128 793]\n",
      " [256 885]\n",
      " [512  52]]\n",
      "log2_max 0.001 100\n",
      "[[  8   2]\n",
      " [ 16  35]\n",
      " [ 32 175]\n",
      " [ 64 473]\n",
      " [128 763]\n",
      " [256 485]\n",
      " [512  67]]\n",
      "log2_max 0.01 20\n",
      "[[ 32  11]\n",
      " [ 64 183]\n",
      " [128 764]\n",
      " [256 957]\n",
      " [512  85]]\n",
      "log2_max 0.01 60\n",
      "[[  8   2]\n",
      " [ 16 121]\n",
      " [ 32 496]\n",
      " [ 64 854]\n",
      " [128 477]\n",
      " [256  50]]\n",
      "log2_max 0.01 100\n",
      "[[  16    1]\n",
      " [  32   63]\n",
      " [  64  344]\n",
      " [ 128  763]\n",
      " [ 256  691]\n",
      " [ 512  137]\n",
      " [1024    1]]\n",
      "log2_max 0.1 20\n",
      "[[ 16   1]\n",
      " [ 32  12]\n",
      " [ 64 157]\n",
      " [128 781]\n",
      " [256 957]\n",
      " [512  92]]\n",
      "log2_max 0.1 60\n",
      "[[ 32  17]\n",
      " [ 64 182]\n",
      " [128 745]\n",
      " [256 959]\n",
      " [512  97]]\n",
      "log2_max 0.1 100\n",
      "[[  8   5]\n",
      " [ 16 108]\n",
      " [ 32 536]\n",
      " [ 64 820]\n",
      " [128 487]\n",
      " [256  44]]\n"
     ]
    }
   ],
   "source": [
    "for game_penalty in ['scores','log2_max']:\n",
    "    for learning_rate in [0.001, 0.01, .1]:\n",
    "        for forget_interval in [20,60,100]:\n",
    "            print(game_penalty, learning_rate, forget_interval)\n",
    "            network = NeuralNetwork()\n",
    "            network.train(duration=1, move_penalty_type='nonzero', forget_after=forget_interval,\n",
    "                     game_penalty_type=game_penalty, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores nonzero 0.001\n",
      "[[ 16   1]\n",
      " [ 32  10]\n",
      " [ 64 178]\n",
      " [128 801]\n",
      " [256 891]\n",
      " [512 119]]\n",
      "scores nonzero 0.01\n",
      "[[ 16   2]\n",
      " [ 32  47]\n",
      " [ 64 269]\n",
      " [128 774]\n",
      " [256 863]\n",
      " [512  45]]\n",
      "scores nonzero 0.1\n",
      "[[ 32  11]\n",
      " [ 64 170]\n",
      " [128 851]\n",
      " [256 876]\n",
      " [512  92]]\n",
      "scores linear_move_num 0.001\n",
      "[[ 16   3]\n",
      " [ 32  53]\n",
      " [ 64 310]\n",
      " [128 766]\n",
      " [256 799]\n",
      " [512  69]]\n",
      "scores linear_move_num 0.01\n",
      "[[ 16   4]\n",
      " [ 32  31]\n",
      " [ 64 239]\n",
      " [128 772]\n",
      " [256 892]\n",
      " [512  62]]\n",
      "scores linear_move_num 0.1\n",
      "[[ 32  21]\n",
      " [ 64 290]\n",
      " [128 872]\n",
      " [256 776]\n",
      " [512  41]]\n",
      "log2_max nonzero 0.001\n",
      "[[ 16   4]\n",
      " [ 32  42]\n",
      " [ 64 247]\n",
      " [128 778]\n",
      " [256 881]\n",
      " [512  48]]\n",
      "log2_max nonzero 0.01\n",
      "[[ 16   5]\n",
      " [ 32  32]\n",
      " [ 64 299]\n",
      " [128 853]\n",
      " [256 743]\n",
      " [512  68]]\n",
      "log2_max nonzero 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mpaige\\Documents\\2048\\helper.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights = weights/weights.sum()\n",
      "C:\\Users\\mpaige\\Documents\\2048\\helper.py:68: RuntimeWarning: invalid value encountered in less\n",
      "  win_idx = np.random.choice(range(len(lst)), p=weights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32  10]\n",
      " [ 64 175]\n",
      " [128 801]\n",
      " [256 916]\n",
      " [512  98]]\n",
      "log2_max linear_move_num 0.001\n",
      "[[  8   1]\n",
      " [ 16 108]\n",
      " [ 32 383]\n",
      " [ 64 712]\n",
      " [128 622]\n",
      " [256 168]\n",
      " [512   6]]\n",
      "log2_max linear_move_num 0.01\n",
      "[[ 16   3]\n",
      " [ 32  38]\n",
      " [ 64 240]\n",
      " [128 733]\n",
      " [256 926]\n",
      " [512  60]]\n",
      "log2_max linear_move_num 0.1\n",
      "[[  8   9]\n",
      " [ 16 121]\n",
      " [ 32 478]\n",
      " [ 64 829]\n",
      " [128 523]\n",
      " [256  40]]\n"
     ]
    }
   ],
   "source": [
    "for game_penalty in ['scores','tile_sums']:\n",
    "    for move_penalty in ['nonzero','linear_move_num']:\n",
    "        for learning_rate in [0.001, 0.01, .1]:\n",
    "            print(game_penalty, move_penalty, learning_rate)\n",
    "            network = NeuralNetwork()\n",
    "            network.train(duration=1, move_penalty_type=move_penalty,\n",
    "                     game_penalty_type=game_penalty, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16   2]\n",
      " [ 32  37]\n",
      " [ 64 282]\n",
      " [128 782]\n",
      " [256 766]\n",
      " [512 131]]\n",
      "[[ 16   1]\n",
      " [ 32  23]\n",
      " [ 64 242]\n",
      " [128 776]\n",
      " [256 885]\n",
      " [512  73]]\n",
      "[[ 32  14]\n",
      " [ 64 170]\n",
      " [128 803]\n",
      " [256 903]\n",
      " [512 110]]\n",
      "[[  8   1]\n",
      " [ 16  17]\n",
      " [ 32 128]\n",
      " [ 64 571]\n",
      " [128 842]\n",
      " [256 405]\n",
      " [512  36]]\n",
      "[[ 32  49]\n",
      " [ 64 269]\n",
      " [128 870]\n",
      " [256 747]\n",
      " [512  65]]\n",
      "[[ 32  13]\n",
      " [ 64 171]\n",
      " [128 788]\n",
      " [256 937]\n",
      " [512  91]]\n",
      "[[ 32  14]\n",
      " [ 64 190]\n",
      " [128 795]\n",
      " [256 895]\n",
      " [512 106]]\n",
      "[[ 16   1]\n",
      " [ 32  52]\n",
      " [ 64 239]\n",
      " [128 634]\n",
      " [256 947]\n",
      " [512 127]]\n",
      "[[ 16   1]\n",
      " [ 32   7]\n",
      " [ 64 183]\n",
      " [128 764]\n",
      " [256 967]\n",
      " [512  78]]\n",
      "[[  8   4]\n",
      " [ 16 117]\n",
      " [ 32 540]\n",
      " [ 64 858]\n",
      " [128 439]\n",
      " [256  41]\n",
      " [512   1]]\n",
      "[[ 32  18]\n",
      " [ 64 173]\n",
      " [128 739]\n",
      " [256 948]\n",
      " [512 122]]\n",
      "[[ 32  30]\n",
      " [ 64 263]\n",
      " [128 789]\n",
      " [256 811]\n",
      " [512 107]]\n",
      "[[ 16  20]\n",
      " [ 32 108]\n",
      " [ 64 409]\n",
      " [128 816]\n",
      " [256 598]\n",
      " [512  49]]\n",
      "[[ 16   4]\n",
      " [ 32  40]\n",
      " [ 64 272]\n",
      " [128 763]\n",
      " [256 867]\n",
      " [512  54]]\n",
      "[[ 32  34]\n",
      " [ 64 291]\n",
      " [128 791]\n",
      " [256 797]\n",
      " [512  87]]\n",
      "[[  16    1]\n",
      " [  32   45]\n",
      " [  64  241]\n",
      " [ 128  634]\n",
      " [ 256  946]\n",
      " [ 512  132]\n",
      " [1024    1]]\n"
     ]
    }
   ],
   "source": [
    "for move_penalty in [None,'nonzero','linear_move_num','exponential_move_num']:\n",
    "    for game_penalty in ['scores','max','log2_max','tile_sums']:\n",
    "        network = NeuralNetwork()\n",
    "        network.train(duration=1, move_penalty_type=move_penalty,\n",
    "                     game_penalty_type=game_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# mini-iterative, random_games=True, 5 hours\n",
    "baseline = pd.DataFrame([[ 16,   0],\n",
    " [  32,   32],\n",
    " [  64,  351],\n",
    " [ 128, 1020],\n",
    " [ 256,  556],\n",
    " [ 512,   41]])\n",
    "\n",
    "\n",
    "\n",
    "after = pd.DataFrame([[ 16,   1],\n",
    " [ 32,  20],\n",
    " [ 64, 236],\n",
    " [128, 758],\n",
    " [256, 910],\n",
    " [512,  75]])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex=True, sharey=True)\n",
    "\n",
    "ax1.bar(baseline[0].astype(str), before[1])\n",
    "ax1.set_ylabel('Before')\n",
    "\n",
    "ax2.bar(after[0].astype(str), after[1])\n",
    "ax2.set_ylabel('After')\n",
    "\n",
    "fig.suptitle('Number of games reaching tile value,\\nbefore and after training')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'random_games':[False, True],\n",
    "         'random_frac':[None, np.random.uniform(0, 1)],\n",
    "         'batch_size':10,\n",
    "          'lr':0.001,\n",
    "         'move_penalty_type':[None,'nonzero','linear_move_num','exponential_move_num'],\n",
    "         'game_penalty_type':['scores','max','log2_max','tile_sums']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test parameter combinations\n",
    "\n",
    "for game_type in params['game_type']:\n",
    "    for random_games in params['random_games']:\n",
    "        for random_frac in params['random_frac']:\n",
    "            for move_penalty_type in params['move_penalty_type']:\n",
    "                for game_penalty_type in params['game_penalty_type']:\n",
    "                    network.train(test=True, duration=1/60000,\n",
    "                                 game_type=game_type, random_games=random_games, random_frac=random_frac,\n",
    "                                 move_penalty_type=move_penalty_type, game_penalty_type=game_penalty_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
